// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Contains details about a variant of the prompt.</p>
#[non_exhaustive]
#[cfg_attr(feature = "serde-serialize", derive(::serde::Serialize))]
#[cfg_attr(feature = "serde-deserialize", derive(::serde::Deserialize))]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq)]
pub struct PromptVariant {
    /// <p>The name of the prompt variant.</p>
    pub name: ::std::string::String,
    /// <p>The type of prompt template to use.</p>
    pub template_type: crate::types::PromptTemplateType,
    /// <p>Contains configurations for the prompt template.</p>
    pub template_configuration: ::std::option::Option<crate::types::PromptTemplateConfiguration>,
    /// <p>The unique identifier of the model or <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/cross-region-inference.html">inference profile</a> with which to run inference on the prompt.</p>
    pub model_id: ::std::option::Option<::std::string::String>,
    /// <p>Contains inference configurations for the prompt variant.</p>
    pub inference_configuration: ::std::option::Option<crate::types::PromptInferenceConfiguration>,
    /// <p>An array of objects, each containing a key-value pair that defines a metadata tag and value to attach to a prompt variant.</p>
    pub metadata: ::std::option::Option<::std::vec::Vec<crate::types::PromptMetadataEntry>>,
    /// <p>Contains model-specific inference configurations that aren't in the <code>inferenceConfiguration</code> field. To see model-specific inference parameters, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html">Inference request parameters and response fields for foundation models</a>.</p>
    pub additional_model_request_fields: ::std::option::Option<::aws_smithy_types::Document>,
    /// <p>Specifies a generative AI resource with which to use the prompt.</p>
    pub gen_ai_resource: ::std::option::Option<crate::types::PromptGenAiResource>,
}
impl PromptVariant {
    /// <p>The name of the prompt variant.</p>
    pub fn name(&self) -> &str {
        use std::ops::Deref;
        self.name.deref()
    }
    /// <p>The type of prompt template to use.</p>
    pub fn template_type(&self) -> &crate::types::PromptTemplateType {
        &self.template_type
    }
    /// <p>Contains configurations for the prompt template.</p>
    pub fn template_configuration(&self) -> ::std::option::Option<&crate::types::PromptTemplateConfiguration> {
        self.template_configuration.as_ref()
    }
    /// <p>The unique identifier of the model or <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/cross-region-inference.html">inference profile</a> with which to run inference on the prompt.</p>
    pub fn model_id(&self) -> ::std::option::Option<&str> {
        self.model_id.as_deref()
    }
    /// <p>Contains inference configurations for the prompt variant.</p>
    pub fn inference_configuration(&self) -> ::std::option::Option<&crate::types::PromptInferenceConfiguration> {
        self.inference_configuration.as_ref()
    }
    /// <p>An array of objects, each containing a key-value pair that defines a metadata tag and value to attach to a prompt variant.</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.metadata.is_none()`.
    pub fn metadata(&self) -> &[crate::types::PromptMetadataEntry] {
        self.metadata.as_deref().unwrap_or_default()
    }
    /// <p>Contains model-specific inference configurations that aren't in the <code>inferenceConfiguration</code> field. To see model-specific inference parameters, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html">Inference request parameters and response fields for foundation models</a>.</p>
    pub fn additional_model_request_fields(&self) -> ::std::option::Option<&::aws_smithy_types::Document> {
        self.additional_model_request_fields.as_ref()
    }
    /// <p>Specifies a generative AI resource with which to use the prompt.</p>
    pub fn gen_ai_resource(&self) -> ::std::option::Option<&crate::types::PromptGenAiResource> {
        self.gen_ai_resource.as_ref()
    }
}
impl ::std::fmt::Debug for PromptVariant {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        let mut formatter = f.debug_struct("PromptVariant");
        formatter.field("name", &"*** Sensitive Data Redacted ***");
        formatter.field("template_type", &"*** Sensitive Data Redacted ***");
        formatter.field("template_configuration", &"*** Sensitive Data Redacted ***");
        formatter.field("model_id", &"*** Sensitive Data Redacted ***");
        formatter.field("inference_configuration", &"*** Sensitive Data Redacted ***");
        formatter.field("metadata", &"*** Sensitive Data Redacted ***");
        formatter.field("additional_model_request_fields", &"*** Sensitive Data Redacted ***");
        formatter.field("gen_ai_resource", &"*** Sensitive Data Redacted ***");
        formatter.finish()
    }
}
impl PromptVariant {
    /// Creates a new builder-style object to manufacture [`PromptVariant`](crate::types::PromptVariant).
    pub fn builder() -> crate::types::builders::PromptVariantBuilder {
        crate::types::builders::PromptVariantBuilder::default()
    }
}

/// A builder for [`PromptVariant`](crate::types::PromptVariant).
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default)]
#[non_exhaustive]
pub struct PromptVariantBuilder {
    pub(crate) name: ::std::option::Option<::std::string::String>,
    pub(crate) template_type: ::std::option::Option<crate::types::PromptTemplateType>,
    pub(crate) template_configuration: ::std::option::Option<crate::types::PromptTemplateConfiguration>,
    pub(crate) model_id: ::std::option::Option<::std::string::String>,
    pub(crate) inference_configuration: ::std::option::Option<crate::types::PromptInferenceConfiguration>,
    pub(crate) metadata: ::std::option::Option<::std::vec::Vec<crate::types::PromptMetadataEntry>>,
    pub(crate) additional_model_request_fields: ::std::option::Option<::aws_smithy_types::Document>,
    pub(crate) gen_ai_resource: ::std::option::Option<crate::types::PromptGenAiResource>,
}
impl PromptVariantBuilder {
    /// <p>The name of the prompt variant.</p>
    /// This field is required.
    pub fn name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The name of the prompt variant.</p>
    pub fn set_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.name = input;
        self
    }
    /// <p>The name of the prompt variant.</p>
    pub fn get_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.name
    }
    /// <p>The type of prompt template to use.</p>
    /// This field is required.
    pub fn template_type(mut self, input: crate::types::PromptTemplateType) -> Self {
        self.template_type = ::std::option::Option::Some(input);
        self
    }
    /// <p>The type of prompt template to use.</p>
    pub fn set_template_type(mut self, input: ::std::option::Option<crate::types::PromptTemplateType>) -> Self {
        self.template_type = input;
        self
    }
    /// <p>The type of prompt template to use.</p>
    pub fn get_template_type(&self) -> &::std::option::Option<crate::types::PromptTemplateType> {
        &self.template_type
    }
    /// <p>Contains configurations for the prompt template.</p>
    /// This field is required.
    pub fn template_configuration(mut self, input: crate::types::PromptTemplateConfiguration) -> Self {
        self.template_configuration = ::std::option::Option::Some(input);
        self
    }
    /// <p>Contains configurations for the prompt template.</p>
    pub fn set_template_configuration(mut self, input: ::std::option::Option<crate::types::PromptTemplateConfiguration>) -> Self {
        self.template_configuration = input;
        self
    }
    /// <p>Contains configurations for the prompt template.</p>
    pub fn get_template_configuration(&self) -> &::std::option::Option<crate::types::PromptTemplateConfiguration> {
        &self.template_configuration
    }
    /// <p>The unique identifier of the model or <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/cross-region-inference.html">inference profile</a> with which to run inference on the prompt.</p>
    pub fn model_id(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.model_id = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The unique identifier of the model or <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/cross-region-inference.html">inference profile</a> with which to run inference on the prompt.</p>
    pub fn set_model_id(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.model_id = input;
        self
    }
    /// <p>The unique identifier of the model or <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/cross-region-inference.html">inference profile</a> with which to run inference on the prompt.</p>
    pub fn get_model_id(&self) -> &::std::option::Option<::std::string::String> {
        &self.model_id
    }
    /// <p>Contains inference configurations for the prompt variant.</p>
    pub fn inference_configuration(mut self, input: crate::types::PromptInferenceConfiguration) -> Self {
        self.inference_configuration = ::std::option::Option::Some(input);
        self
    }
    /// <p>Contains inference configurations for the prompt variant.</p>
    pub fn set_inference_configuration(mut self, input: ::std::option::Option<crate::types::PromptInferenceConfiguration>) -> Self {
        self.inference_configuration = input;
        self
    }
    /// <p>Contains inference configurations for the prompt variant.</p>
    pub fn get_inference_configuration(&self) -> &::std::option::Option<crate::types::PromptInferenceConfiguration> {
        &self.inference_configuration
    }
    /// Appends an item to `metadata`.
    ///
    /// To override the contents of this collection use [`set_metadata`](Self::set_metadata).
    ///
    /// <p>An array of objects, each containing a key-value pair that defines a metadata tag and value to attach to a prompt variant.</p>
    pub fn metadata(mut self, input: crate::types::PromptMetadataEntry) -> Self {
        let mut v = self.metadata.unwrap_or_default();
        v.push(input);
        self.metadata = ::std::option::Option::Some(v);
        self
    }
    /// <p>An array of objects, each containing a key-value pair that defines a metadata tag and value to attach to a prompt variant.</p>
    pub fn set_metadata(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::PromptMetadataEntry>>) -> Self {
        self.metadata = input;
        self
    }
    /// <p>An array of objects, each containing a key-value pair that defines a metadata tag and value to attach to a prompt variant.</p>
    pub fn get_metadata(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::PromptMetadataEntry>> {
        &self.metadata
    }
    /// <p>Contains model-specific inference configurations that aren't in the <code>inferenceConfiguration</code> field. To see model-specific inference parameters, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html">Inference request parameters and response fields for foundation models</a>.</p>
    pub fn additional_model_request_fields(mut self, input: ::aws_smithy_types::Document) -> Self {
        self.additional_model_request_fields = ::std::option::Option::Some(input);
        self
    }
    /// <p>Contains model-specific inference configurations that aren't in the <code>inferenceConfiguration</code> field. To see model-specific inference parameters, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html">Inference request parameters and response fields for foundation models</a>.</p>
    pub fn set_additional_model_request_fields(mut self, input: ::std::option::Option<::aws_smithy_types::Document>) -> Self {
        self.additional_model_request_fields = input;
        self
    }
    /// <p>Contains model-specific inference configurations that aren't in the <code>inferenceConfiguration</code> field. To see model-specific inference parameters, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html">Inference request parameters and response fields for foundation models</a>.</p>
    pub fn get_additional_model_request_fields(&self) -> &::std::option::Option<::aws_smithy_types::Document> {
        &self.additional_model_request_fields
    }
    /// <p>Specifies a generative AI resource with which to use the prompt.</p>
    pub fn gen_ai_resource(mut self, input: crate::types::PromptGenAiResource) -> Self {
        self.gen_ai_resource = ::std::option::Option::Some(input);
        self
    }
    /// <p>Specifies a generative AI resource with which to use the prompt.</p>
    pub fn set_gen_ai_resource(mut self, input: ::std::option::Option<crate::types::PromptGenAiResource>) -> Self {
        self.gen_ai_resource = input;
        self
    }
    /// <p>Specifies a generative AI resource with which to use the prompt.</p>
    pub fn get_gen_ai_resource(&self) -> &::std::option::Option<crate::types::PromptGenAiResource> {
        &self.gen_ai_resource
    }
    /// Consumes the builder and constructs a [`PromptVariant`](crate::types::PromptVariant).
    /// This method will fail if any of the following fields are not set:
    /// - [`name`](crate::types::builders::PromptVariantBuilder::name)
    /// - [`template_type`](crate::types::builders::PromptVariantBuilder::template_type)
    pub fn build(self) -> ::std::result::Result<crate::types::PromptVariant, ::aws_smithy_types::error::operation::BuildError> {
        ::std::result::Result::Ok(crate::types::PromptVariant {
            name: self.name.ok_or_else(|| {
                ::aws_smithy_types::error::operation::BuildError::missing_field(
                    "name",
                    "name was not specified but it is required when building PromptVariant",
                )
            })?,
            template_type: self.template_type.ok_or_else(|| {
                ::aws_smithy_types::error::operation::BuildError::missing_field(
                    "template_type",
                    "template_type was not specified but it is required when building PromptVariant",
                )
            })?,
            template_configuration: self.template_configuration,
            model_id: self.model_id,
            inference_configuration: self.inference_configuration,
            metadata: self.metadata,
            additional_model_request_fields: self.additional_model_request_fields,
            gen_ai_resource: self.gen_ai_resource,
        })
    }
}
impl ::std::fmt::Debug for PromptVariantBuilder {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        let mut formatter = f.debug_struct("PromptVariantBuilder");
        formatter.field("name", &"*** Sensitive Data Redacted ***");
        formatter.field("template_type", &"*** Sensitive Data Redacted ***");
        formatter.field("template_configuration", &"*** Sensitive Data Redacted ***");
        formatter.field("model_id", &"*** Sensitive Data Redacted ***");
        formatter.field("inference_configuration", &"*** Sensitive Data Redacted ***");
        formatter.field("metadata", &"*** Sensitive Data Redacted ***");
        formatter.field("additional_model_request_fields", &"*** Sensitive Data Redacted ***");
        formatter.field("gen_ai_resource", &"*** Sensitive Data Redacted ***");
        formatter.finish()
    }
}
