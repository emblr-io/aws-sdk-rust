// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Contains configurations to override a prompt template in one part of an agent sequence. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/advanced-prompts.html">Advanced prompts</a>.</p>
#[non_exhaustive]
#[cfg_attr(feature = "serde-serialize", derive(::serde::Serialize))]
#[cfg_attr(feature = "serde-deserialize", derive(::serde::Deserialize))]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq)]
pub struct PromptConfiguration {
    /// <p>The step in the agent sequence that this prompt configuration applies to.</p>
    pub prompt_type: ::std::option::Option<crate::types::PromptType>,
    /// <p>Specifies whether to override the default prompt template for this <code>promptType</code>. Set this value to <code>OVERRIDDEN</code> to use the prompt that you provide in the <code>basePromptTemplate</code>. If you leave it as <code>DEFAULT</code>, the agent uses a default prompt template.</p>
    pub prompt_creation_mode: ::std::option::Option<crate::types::CreationMode>,
    /// <p>Specifies whether to allow the agent to carry out the step specified in the <code>promptType</code>. If you set this value to <code>DISABLED</code>, the agent skips that step. The default state for each <code>promptType</code> is as follows.</p>
    /// <ul>
    /// <li>
    /// <p><code>PRE_PROCESSING</code> – <code>DISABLED</code></p></li>
    /// <li>
    /// <p><code>ORCHESTRATION</code> – <code>ENABLED</code></p></li>
    /// <li>
    /// <p><code>KNOWLEDGE_BASE_RESPONSE_GENERATION</code> – <code>ENABLED</code></p></li>
    /// <li>
    /// <p><code>POST_PROCESSING</code> – <code>DISABLED</code></p></li>
    /// </ul>
    pub prompt_state: ::std::option::Option<crate::types::PromptState>,
    /// <p>Defines the prompt template with which to replace the default prompt template. You can use placeholder variables in the base prompt template to customize the prompt. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-placeholders.html">Prompt template placeholder variables</a>. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/advanced-prompts-configure.html">Configure the prompt templates</a>.</p>
    pub base_prompt_template: ::std::option::Option<::std::string::String>,
    /// <p>Contains inference parameters to use when the agent invokes a foundation model in the part of the agent sequence defined by the <code>promptType</code>. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html">Inference parameters for foundation models</a>.</p>
    pub inference_configuration: ::std::option::Option<crate::types::InferenceConfiguration>,
    /// <p>Specifies whether to override the default parser Lambda function when parsing the raw foundation model output in the part of the agent sequence defined by the <code>promptType</code>. If you set the field as <code>OVERRIDDEN</code>, the <code>overrideLambda</code> field in the <a href="https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent_PromptOverrideConfiguration.html">PromptOverrideConfiguration</a> must be specified with the ARN of a Lambda function.</p>
    pub parser_mode: ::std::option::Option<crate::types::CreationMode>,
    /// <p>The agent's foundation model.</p>
    pub foundation_model: ::std::option::Option<::std::string::String>,
    /// <p>If the Converse or ConverseStream operations support the model, <code>additionalModelRequestFields</code> contains additional inference parameters, beyond the base set of inference parameters in the <code>inferenceConfiguration</code> field.</p>
    /// <p>For more information, see <i>Inference request parameters and response fields for foundation models</i> in the Amazon Bedrock user guide.</p>
    pub additional_model_request_fields: ::std::option::Option<::aws_smithy_types::Document>,
}
impl PromptConfiguration {
    /// <p>The step in the agent sequence that this prompt configuration applies to.</p>
    pub fn prompt_type(&self) -> ::std::option::Option<&crate::types::PromptType> {
        self.prompt_type.as_ref()
    }
    /// <p>Specifies whether to override the default prompt template for this <code>promptType</code>. Set this value to <code>OVERRIDDEN</code> to use the prompt that you provide in the <code>basePromptTemplate</code>. If you leave it as <code>DEFAULT</code>, the agent uses a default prompt template.</p>
    pub fn prompt_creation_mode(&self) -> ::std::option::Option<&crate::types::CreationMode> {
        self.prompt_creation_mode.as_ref()
    }
    /// <p>Specifies whether to allow the agent to carry out the step specified in the <code>promptType</code>. If you set this value to <code>DISABLED</code>, the agent skips that step. The default state for each <code>promptType</code> is as follows.</p>
    /// <ul>
    /// <li>
    /// <p><code>PRE_PROCESSING</code> – <code>DISABLED</code></p></li>
    /// <li>
    /// <p><code>ORCHESTRATION</code> – <code>ENABLED</code></p></li>
    /// <li>
    /// <p><code>KNOWLEDGE_BASE_RESPONSE_GENERATION</code> – <code>ENABLED</code></p></li>
    /// <li>
    /// <p><code>POST_PROCESSING</code> – <code>DISABLED</code></p></li>
    /// </ul>
    pub fn prompt_state(&self) -> ::std::option::Option<&crate::types::PromptState> {
        self.prompt_state.as_ref()
    }
    /// <p>Defines the prompt template with which to replace the default prompt template. You can use placeholder variables in the base prompt template to customize the prompt. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-placeholders.html">Prompt template placeholder variables</a>. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/advanced-prompts-configure.html">Configure the prompt templates</a>.</p>
    pub fn base_prompt_template(&self) -> ::std::option::Option<&str> {
        self.base_prompt_template.as_deref()
    }
    /// <p>Contains inference parameters to use when the agent invokes a foundation model in the part of the agent sequence defined by the <code>promptType</code>. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html">Inference parameters for foundation models</a>.</p>
    pub fn inference_configuration(&self) -> ::std::option::Option<&crate::types::InferenceConfiguration> {
        self.inference_configuration.as_ref()
    }
    /// <p>Specifies whether to override the default parser Lambda function when parsing the raw foundation model output in the part of the agent sequence defined by the <code>promptType</code>. If you set the field as <code>OVERRIDDEN</code>, the <code>overrideLambda</code> field in the <a href="https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent_PromptOverrideConfiguration.html">PromptOverrideConfiguration</a> must be specified with the ARN of a Lambda function.</p>
    pub fn parser_mode(&self) -> ::std::option::Option<&crate::types::CreationMode> {
        self.parser_mode.as_ref()
    }
    /// <p>The agent's foundation model.</p>
    pub fn foundation_model(&self) -> ::std::option::Option<&str> {
        self.foundation_model.as_deref()
    }
    /// <p>If the Converse or ConverseStream operations support the model, <code>additionalModelRequestFields</code> contains additional inference parameters, beyond the base set of inference parameters in the <code>inferenceConfiguration</code> field.</p>
    /// <p>For more information, see <i>Inference request parameters and response fields for foundation models</i> in the Amazon Bedrock user guide.</p>
    pub fn additional_model_request_fields(&self) -> ::std::option::Option<&::aws_smithy_types::Document> {
        self.additional_model_request_fields.as_ref()
    }
}
impl ::std::fmt::Debug for PromptConfiguration {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        let mut formatter = f.debug_struct("PromptConfiguration");
        formatter.field("prompt_type", &self.prompt_type);
        formatter.field("prompt_creation_mode", &self.prompt_creation_mode);
        formatter.field("prompt_state", &self.prompt_state);
        formatter.field("base_prompt_template", &"*** Sensitive Data Redacted ***");
        formatter.field("inference_configuration", &self.inference_configuration);
        formatter.field("parser_mode", &self.parser_mode);
        formatter.field("foundation_model", &self.foundation_model);
        formatter.field("additional_model_request_fields", &self.additional_model_request_fields);
        formatter.finish()
    }
}
impl PromptConfiguration {
    /// Creates a new builder-style object to manufacture [`PromptConfiguration`](crate::types::PromptConfiguration).
    pub fn builder() -> crate::types::builders::PromptConfigurationBuilder {
        crate::types::builders::PromptConfigurationBuilder::default()
    }
}

/// A builder for [`PromptConfiguration`](crate::types::PromptConfiguration).
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default)]
#[non_exhaustive]
pub struct PromptConfigurationBuilder {
    pub(crate) prompt_type: ::std::option::Option<crate::types::PromptType>,
    pub(crate) prompt_creation_mode: ::std::option::Option<crate::types::CreationMode>,
    pub(crate) prompt_state: ::std::option::Option<crate::types::PromptState>,
    pub(crate) base_prompt_template: ::std::option::Option<::std::string::String>,
    pub(crate) inference_configuration: ::std::option::Option<crate::types::InferenceConfiguration>,
    pub(crate) parser_mode: ::std::option::Option<crate::types::CreationMode>,
    pub(crate) foundation_model: ::std::option::Option<::std::string::String>,
    pub(crate) additional_model_request_fields: ::std::option::Option<::aws_smithy_types::Document>,
}
impl PromptConfigurationBuilder {
    /// <p>The step in the agent sequence that this prompt configuration applies to.</p>
    pub fn prompt_type(mut self, input: crate::types::PromptType) -> Self {
        self.prompt_type = ::std::option::Option::Some(input);
        self
    }
    /// <p>The step in the agent sequence that this prompt configuration applies to.</p>
    pub fn set_prompt_type(mut self, input: ::std::option::Option<crate::types::PromptType>) -> Self {
        self.prompt_type = input;
        self
    }
    /// <p>The step in the agent sequence that this prompt configuration applies to.</p>
    pub fn get_prompt_type(&self) -> &::std::option::Option<crate::types::PromptType> {
        &self.prompt_type
    }
    /// <p>Specifies whether to override the default prompt template for this <code>promptType</code>. Set this value to <code>OVERRIDDEN</code> to use the prompt that you provide in the <code>basePromptTemplate</code>. If you leave it as <code>DEFAULT</code>, the agent uses a default prompt template.</p>
    pub fn prompt_creation_mode(mut self, input: crate::types::CreationMode) -> Self {
        self.prompt_creation_mode = ::std::option::Option::Some(input);
        self
    }
    /// <p>Specifies whether to override the default prompt template for this <code>promptType</code>. Set this value to <code>OVERRIDDEN</code> to use the prompt that you provide in the <code>basePromptTemplate</code>. If you leave it as <code>DEFAULT</code>, the agent uses a default prompt template.</p>
    pub fn set_prompt_creation_mode(mut self, input: ::std::option::Option<crate::types::CreationMode>) -> Self {
        self.prompt_creation_mode = input;
        self
    }
    /// <p>Specifies whether to override the default prompt template for this <code>promptType</code>. Set this value to <code>OVERRIDDEN</code> to use the prompt that you provide in the <code>basePromptTemplate</code>. If you leave it as <code>DEFAULT</code>, the agent uses a default prompt template.</p>
    pub fn get_prompt_creation_mode(&self) -> &::std::option::Option<crate::types::CreationMode> {
        &self.prompt_creation_mode
    }
    /// <p>Specifies whether to allow the agent to carry out the step specified in the <code>promptType</code>. If you set this value to <code>DISABLED</code>, the agent skips that step. The default state for each <code>promptType</code> is as follows.</p>
    /// <ul>
    /// <li>
    /// <p><code>PRE_PROCESSING</code> – <code>DISABLED</code></p></li>
    /// <li>
    /// <p><code>ORCHESTRATION</code> – <code>ENABLED</code></p></li>
    /// <li>
    /// <p><code>KNOWLEDGE_BASE_RESPONSE_GENERATION</code> – <code>ENABLED</code></p></li>
    /// <li>
    /// <p><code>POST_PROCESSING</code> – <code>DISABLED</code></p></li>
    /// </ul>
    pub fn prompt_state(mut self, input: crate::types::PromptState) -> Self {
        self.prompt_state = ::std::option::Option::Some(input);
        self
    }
    /// <p>Specifies whether to allow the agent to carry out the step specified in the <code>promptType</code>. If you set this value to <code>DISABLED</code>, the agent skips that step. The default state for each <code>promptType</code> is as follows.</p>
    /// <ul>
    /// <li>
    /// <p><code>PRE_PROCESSING</code> – <code>DISABLED</code></p></li>
    /// <li>
    /// <p><code>ORCHESTRATION</code> – <code>ENABLED</code></p></li>
    /// <li>
    /// <p><code>KNOWLEDGE_BASE_RESPONSE_GENERATION</code> – <code>ENABLED</code></p></li>
    /// <li>
    /// <p><code>POST_PROCESSING</code> – <code>DISABLED</code></p></li>
    /// </ul>
    pub fn set_prompt_state(mut self, input: ::std::option::Option<crate::types::PromptState>) -> Self {
        self.prompt_state = input;
        self
    }
    /// <p>Specifies whether to allow the agent to carry out the step specified in the <code>promptType</code>. If you set this value to <code>DISABLED</code>, the agent skips that step. The default state for each <code>promptType</code> is as follows.</p>
    /// <ul>
    /// <li>
    /// <p><code>PRE_PROCESSING</code> – <code>DISABLED</code></p></li>
    /// <li>
    /// <p><code>ORCHESTRATION</code> – <code>ENABLED</code></p></li>
    /// <li>
    /// <p><code>KNOWLEDGE_BASE_RESPONSE_GENERATION</code> – <code>ENABLED</code></p></li>
    /// <li>
    /// <p><code>POST_PROCESSING</code> – <code>DISABLED</code></p></li>
    /// </ul>
    pub fn get_prompt_state(&self) -> &::std::option::Option<crate::types::PromptState> {
        &self.prompt_state
    }
    /// <p>Defines the prompt template with which to replace the default prompt template. You can use placeholder variables in the base prompt template to customize the prompt. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-placeholders.html">Prompt template placeholder variables</a>. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/advanced-prompts-configure.html">Configure the prompt templates</a>.</p>
    pub fn base_prompt_template(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.base_prompt_template = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Defines the prompt template with which to replace the default prompt template. You can use placeholder variables in the base prompt template to customize the prompt. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-placeholders.html">Prompt template placeholder variables</a>. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/advanced-prompts-configure.html">Configure the prompt templates</a>.</p>
    pub fn set_base_prompt_template(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.base_prompt_template = input;
        self
    }
    /// <p>Defines the prompt template with which to replace the default prompt template. You can use placeholder variables in the base prompt template to customize the prompt. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-placeholders.html">Prompt template placeholder variables</a>. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/advanced-prompts-configure.html">Configure the prompt templates</a>.</p>
    pub fn get_base_prompt_template(&self) -> &::std::option::Option<::std::string::String> {
        &self.base_prompt_template
    }
    /// <p>Contains inference parameters to use when the agent invokes a foundation model in the part of the agent sequence defined by the <code>promptType</code>. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html">Inference parameters for foundation models</a>.</p>
    pub fn inference_configuration(mut self, input: crate::types::InferenceConfiguration) -> Self {
        self.inference_configuration = ::std::option::Option::Some(input);
        self
    }
    /// <p>Contains inference parameters to use when the agent invokes a foundation model in the part of the agent sequence defined by the <code>promptType</code>. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html">Inference parameters for foundation models</a>.</p>
    pub fn set_inference_configuration(mut self, input: ::std::option::Option<crate::types::InferenceConfiguration>) -> Self {
        self.inference_configuration = input;
        self
    }
    /// <p>Contains inference parameters to use when the agent invokes a foundation model in the part of the agent sequence defined by the <code>promptType</code>. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html">Inference parameters for foundation models</a>.</p>
    pub fn get_inference_configuration(&self) -> &::std::option::Option<crate::types::InferenceConfiguration> {
        &self.inference_configuration
    }
    /// <p>Specifies whether to override the default parser Lambda function when parsing the raw foundation model output in the part of the agent sequence defined by the <code>promptType</code>. If you set the field as <code>OVERRIDDEN</code>, the <code>overrideLambda</code> field in the <a href="https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent_PromptOverrideConfiguration.html">PromptOverrideConfiguration</a> must be specified with the ARN of a Lambda function.</p>
    pub fn parser_mode(mut self, input: crate::types::CreationMode) -> Self {
        self.parser_mode = ::std::option::Option::Some(input);
        self
    }
    /// <p>Specifies whether to override the default parser Lambda function when parsing the raw foundation model output in the part of the agent sequence defined by the <code>promptType</code>. If you set the field as <code>OVERRIDDEN</code>, the <code>overrideLambda</code> field in the <a href="https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent_PromptOverrideConfiguration.html">PromptOverrideConfiguration</a> must be specified with the ARN of a Lambda function.</p>
    pub fn set_parser_mode(mut self, input: ::std::option::Option<crate::types::CreationMode>) -> Self {
        self.parser_mode = input;
        self
    }
    /// <p>Specifies whether to override the default parser Lambda function when parsing the raw foundation model output in the part of the agent sequence defined by the <code>promptType</code>. If you set the field as <code>OVERRIDDEN</code>, the <code>overrideLambda</code> field in the <a href="https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent_PromptOverrideConfiguration.html">PromptOverrideConfiguration</a> must be specified with the ARN of a Lambda function.</p>
    pub fn get_parser_mode(&self) -> &::std::option::Option<crate::types::CreationMode> {
        &self.parser_mode
    }
    /// <p>The agent's foundation model.</p>
    pub fn foundation_model(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.foundation_model = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The agent's foundation model.</p>
    pub fn set_foundation_model(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.foundation_model = input;
        self
    }
    /// <p>The agent's foundation model.</p>
    pub fn get_foundation_model(&self) -> &::std::option::Option<::std::string::String> {
        &self.foundation_model
    }
    /// <p>If the Converse or ConverseStream operations support the model, <code>additionalModelRequestFields</code> contains additional inference parameters, beyond the base set of inference parameters in the <code>inferenceConfiguration</code> field.</p>
    /// <p>For more information, see <i>Inference request parameters and response fields for foundation models</i> in the Amazon Bedrock user guide.</p>
    pub fn additional_model_request_fields(mut self, input: ::aws_smithy_types::Document) -> Self {
        self.additional_model_request_fields = ::std::option::Option::Some(input);
        self
    }
    /// <p>If the Converse or ConverseStream operations support the model, <code>additionalModelRequestFields</code> contains additional inference parameters, beyond the base set of inference parameters in the <code>inferenceConfiguration</code> field.</p>
    /// <p>For more information, see <i>Inference request parameters and response fields for foundation models</i> in the Amazon Bedrock user guide.</p>
    pub fn set_additional_model_request_fields(mut self, input: ::std::option::Option<::aws_smithy_types::Document>) -> Self {
        self.additional_model_request_fields = input;
        self
    }
    /// <p>If the Converse or ConverseStream operations support the model, <code>additionalModelRequestFields</code> contains additional inference parameters, beyond the base set of inference parameters in the <code>inferenceConfiguration</code> field.</p>
    /// <p>For more information, see <i>Inference request parameters and response fields for foundation models</i> in the Amazon Bedrock user guide.</p>
    pub fn get_additional_model_request_fields(&self) -> &::std::option::Option<::aws_smithy_types::Document> {
        &self.additional_model_request_fields
    }
    /// Consumes the builder and constructs a [`PromptConfiguration`](crate::types::PromptConfiguration).
    pub fn build(self) -> crate::types::PromptConfiguration {
        crate::types::PromptConfiguration {
            prompt_type: self.prompt_type,
            prompt_creation_mode: self.prompt_creation_mode,
            prompt_state: self.prompt_state,
            base_prompt_template: self.base_prompt_template,
            inference_configuration: self.inference_configuration,
            parser_mode: self.parser_mode,
            foundation_model: self.foundation_model,
            additional_model_request_fields: self.additional_model_request_fields,
        }
    }
}
impl ::std::fmt::Debug for PromptConfigurationBuilder {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        let mut formatter = f.debug_struct("PromptConfigurationBuilder");
        formatter.field("prompt_type", &self.prompt_type);
        formatter.field("prompt_creation_mode", &self.prompt_creation_mode);
        formatter.field("prompt_state", &self.prompt_state);
        formatter.field("base_prompt_template", &"*** Sensitive Data Redacted ***");
        formatter.field("inference_configuration", &self.inference_configuration);
        formatter.field("parser_mode", &self.parser_mode);
        formatter.field("foundation_model", &self.foundation_model);
        formatter.field("additional_model_request_fields", &self.additional_model_request_fields);
        formatter.finish()
    }
}
