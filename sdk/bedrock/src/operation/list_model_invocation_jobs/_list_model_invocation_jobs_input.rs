// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[cfg_attr(feature = "serde-serialize", derive(::serde::Serialize))]
#[cfg_attr(feature = "serde-deserialize", derive(::serde::Deserialize))]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct ListModelInvocationJobsInput {
    /// <p>Specify a time to filter for batch inference jobs that were submitted after the time you specify.</p>
    pub submit_time_after: ::std::option::Option<::aws_smithy_types::DateTime>,
    /// <p>Specify a time to filter for batch inference jobs that were submitted before the time you specify.</p>
    pub submit_time_before: ::std::option::Option<::aws_smithy_types::DateTime>,
    /// <p>Specify a status to filter for batch inference jobs whose statuses match the string you specify.</p>
    /// <p>The following statuses are possible:</p>
    /// <ul>
    /// <li>
    /// <p>Submitted – This job has been submitted to a queue for validation.</p></li>
    /// <li>
    /// <p>Validating – This job is being validated for the requirements described in <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-data.html">Format and upload your batch inference data</a>. The criteria include the following:</p>
    /// <ul>
    /// <li>
    /// <p>Your IAM service role has access to the Amazon S3 buckets containing your files.</p></li>
    /// <li>
    /// <p>Your files are .jsonl files and each individual record is a JSON object in the correct format. Note that validation doesn't check if the <code>modelInput</code> value matches the request body for the model.</p></li>
    /// <li>
    /// <p>Your files fulfill the requirements for file size and number of records. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html">Quotas for Amazon Bedrock</a>.</p></li>
    /// </ul></li>
    /// <li>
    /// <p>Scheduled – This job has been validated and is now in a queue. The job will automatically start when it reaches its turn.</p></li>
    /// <li>
    /// <p>Expired – This job timed out because it was scheduled but didn't begin before the set timeout duration. Submit a new job request.</p></li>
    /// <li>
    /// <p>InProgress – This job has begun. You can start viewing the results in the output S3 location.</p></li>
    /// <li>
    /// <p>Completed – This job has successfully completed. View the output files in the output S3 location.</p></li>
    /// <li>
    /// <p>PartiallyCompleted – This job has partially completed. Not all of your records could be processed in time. View the output files in the output S3 location.</p></li>
    /// <li>
    /// <p>Failed – This job has failed. Check the failure message for any further details. For further assistance, reach out to the <a href="https://console.aws.amazon.com/support/home/">Amazon Web ServicesSupport Center</a>.</p></li>
    /// <li>
    /// <p>Stopped – This job was stopped by a user.</p></li>
    /// <li>
    /// <p>Stopping – This job is being stopped by a user.</p></li>
    /// </ul>
    pub status_equals: ::std::option::Option<crate::types::ModelInvocationJobStatus>,
    /// <p>Specify a string to filter for batch inference jobs whose names contain the string.</p>
    pub name_contains: ::std::option::Option<::std::string::String>,
    /// <p>The maximum number of results to return. If there are more results than the number that you specify, a <code>nextToken</code> value is returned. Use the <code>nextToken</code> in a request to return the next batch of results.</p>
    pub max_results: ::std::option::Option<i32>,
    /// <p>If there were more results than the value you specified in the <code>maxResults</code> field in a previous <code>ListModelInvocationJobs</code> request, the response would have returned a <code>nextToken</code> value. To see the next batch of results, send the <code>nextToken</code> value in another request.</p>
    pub next_token: ::std::option::Option<::std::string::String>,
    /// <p>An attribute by which to sort the results.</p>
    pub sort_by: ::std::option::Option<crate::types::SortJobsBy>,
    /// <p>Specifies whether to sort the results by ascending or descending order.</p>
    pub sort_order: ::std::option::Option<crate::types::SortOrder>,
}
impl ListModelInvocationJobsInput {
    /// <p>Specify a time to filter for batch inference jobs that were submitted after the time you specify.</p>
    pub fn submit_time_after(&self) -> ::std::option::Option<&::aws_smithy_types::DateTime> {
        self.submit_time_after.as_ref()
    }
    /// <p>Specify a time to filter for batch inference jobs that were submitted before the time you specify.</p>
    pub fn submit_time_before(&self) -> ::std::option::Option<&::aws_smithy_types::DateTime> {
        self.submit_time_before.as_ref()
    }
    /// <p>Specify a status to filter for batch inference jobs whose statuses match the string you specify.</p>
    /// <p>The following statuses are possible:</p>
    /// <ul>
    /// <li>
    /// <p>Submitted – This job has been submitted to a queue for validation.</p></li>
    /// <li>
    /// <p>Validating – This job is being validated for the requirements described in <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-data.html">Format and upload your batch inference data</a>. The criteria include the following:</p>
    /// <ul>
    /// <li>
    /// <p>Your IAM service role has access to the Amazon S3 buckets containing your files.</p></li>
    /// <li>
    /// <p>Your files are .jsonl files and each individual record is a JSON object in the correct format. Note that validation doesn't check if the <code>modelInput</code> value matches the request body for the model.</p></li>
    /// <li>
    /// <p>Your files fulfill the requirements for file size and number of records. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html">Quotas for Amazon Bedrock</a>.</p></li>
    /// </ul></li>
    /// <li>
    /// <p>Scheduled – This job has been validated and is now in a queue. The job will automatically start when it reaches its turn.</p></li>
    /// <li>
    /// <p>Expired – This job timed out because it was scheduled but didn't begin before the set timeout duration. Submit a new job request.</p></li>
    /// <li>
    /// <p>InProgress – This job has begun. You can start viewing the results in the output S3 location.</p></li>
    /// <li>
    /// <p>Completed – This job has successfully completed. View the output files in the output S3 location.</p></li>
    /// <li>
    /// <p>PartiallyCompleted – This job has partially completed. Not all of your records could be processed in time. View the output files in the output S3 location.</p></li>
    /// <li>
    /// <p>Failed – This job has failed. Check the failure message for any further details. For further assistance, reach out to the <a href="https://console.aws.amazon.com/support/home/">Amazon Web ServicesSupport Center</a>.</p></li>
    /// <li>
    /// <p>Stopped – This job was stopped by a user.</p></li>
    /// <li>
    /// <p>Stopping – This job is being stopped by a user.</p></li>
    /// </ul>
    pub fn status_equals(&self) -> ::std::option::Option<&crate::types::ModelInvocationJobStatus> {
        self.status_equals.as_ref()
    }
    /// <p>Specify a string to filter for batch inference jobs whose names contain the string.</p>
    pub fn name_contains(&self) -> ::std::option::Option<&str> {
        self.name_contains.as_deref()
    }
    /// <p>The maximum number of results to return. If there are more results than the number that you specify, a <code>nextToken</code> value is returned. Use the <code>nextToken</code> in a request to return the next batch of results.</p>
    pub fn max_results(&self) -> ::std::option::Option<i32> {
        self.max_results
    }
    /// <p>If there were more results than the value you specified in the <code>maxResults</code> field in a previous <code>ListModelInvocationJobs</code> request, the response would have returned a <code>nextToken</code> value. To see the next batch of results, send the <code>nextToken</code> value in another request.</p>
    pub fn next_token(&self) -> ::std::option::Option<&str> {
        self.next_token.as_deref()
    }
    /// <p>An attribute by which to sort the results.</p>
    pub fn sort_by(&self) -> ::std::option::Option<&crate::types::SortJobsBy> {
        self.sort_by.as_ref()
    }
    /// <p>Specifies whether to sort the results by ascending or descending order.</p>
    pub fn sort_order(&self) -> ::std::option::Option<&crate::types::SortOrder> {
        self.sort_order.as_ref()
    }
}
impl ListModelInvocationJobsInput {
    /// Creates a new builder-style object to manufacture [`ListModelInvocationJobsInput`](crate::operation::list_model_invocation_jobs::ListModelInvocationJobsInput).
    pub fn builder() -> crate::operation::list_model_invocation_jobs::builders::ListModelInvocationJobsInputBuilder {
        crate::operation::list_model_invocation_jobs::builders::ListModelInvocationJobsInputBuilder::default()
    }
}

/// A builder for [`ListModelInvocationJobsInput`](crate::operation::list_model_invocation_jobs::ListModelInvocationJobsInput).
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
#[non_exhaustive]
pub struct ListModelInvocationJobsInputBuilder {
    pub(crate) submit_time_after: ::std::option::Option<::aws_smithy_types::DateTime>,
    pub(crate) submit_time_before: ::std::option::Option<::aws_smithy_types::DateTime>,
    pub(crate) status_equals: ::std::option::Option<crate::types::ModelInvocationJobStatus>,
    pub(crate) name_contains: ::std::option::Option<::std::string::String>,
    pub(crate) max_results: ::std::option::Option<i32>,
    pub(crate) next_token: ::std::option::Option<::std::string::String>,
    pub(crate) sort_by: ::std::option::Option<crate::types::SortJobsBy>,
    pub(crate) sort_order: ::std::option::Option<crate::types::SortOrder>,
}
impl ListModelInvocationJobsInputBuilder {
    /// <p>Specify a time to filter for batch inference jobs that were submitted after the time you specify.</p>
    pub fn submit_time_after(mut self, input: ::aws_smithy_types::DateTime) -> Self {
        self.submit_time_after = ::std::option::Option::Some(input);
        self
    }
    /// <p>Specify a time to filter for batch inference jobs that were submitted after the time you specify.</p>
    pub fn set_submit_time_after(mut self, input: ::std::option::Option<::aws_smithy_types::DateTime>) -> Self {
        self.submit_time_after = input;
        self
    }
    /// <p>Specify a time to filter for batch inference jobs that were submitted after the time you specify.</p>
    pub fn get_submit_time_after(&self) -> &::std::option::Option<::aws_smithy_types::DateTime> {
        &self.submit_time_after
    }
    /// <p>Specify a time to filter for batch inference jobs that were submitted before the time you specify.</p>
    pub fn submit_time_before(mut self, input: ::aws_smithy_types::DateTime) -> Self {
        self.submit_time_before = ::std::option::Option::Some(input);
        self
    }
    /// <p>Specify a time to filter for batch inference jobs that were submitted before the time you specify.</p>
    pub fn set_submit_time_before(mut self, input: ::std::option::Option<::aws_smithy_types::DateTime>) -> Self {
        self.submit_time_before = input;
        self
    }
    /// <p>Specify a time to filter for batch inference jobs that were submitted before the time you specify.</p>
    pub fn get_submit_time_before(&self) -> &::std::option::Option<::aws_smithy_types::DateTime> {
        &self.submit_time_before
    }
    /// <p>Specify a status to filter for batch inference jobs whose statuses match the string you specify.</p>
    /// <p>The following statuses are possible:</p>
    /// <ul>
    /// <li>
    /// <p>Submitted – This job has been submitted to a queue for validation.</p></li>
    /// <li>
    /// <p>Validating – This job is being validated for the requirements described in <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-data.html">Format and upload your batch inference data</a>. The criteria include the following:</p>
    /// <ul>
    /// <li>
    /// <p>Your IAM service role has access to the Amazon S3 buckets containing your files.</p></li>
    /// <li>
    /// <p>Your files are .jsonl files and each individual record is a JSON object in the correct format. Note that validation doesn't check if the <code>modelInput</code> value matches the request body for the model.</p></li>
    /// <li>
    /// <p>Your files fulfill the requirements for file size and number of records. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html">Quotas for Amazon Bedrock</a>.</p></li>
    /// </ul></li>
    /// <li>
    /// <p>Scheduled – This job has been validated and is now in a queue. The job will automatically start when it reaches its turn.</p></li>
    /// <li>
    /// <p>Expired – This job timed out because it was scheduled but didn't begin before the set timeout duration. Submit a new job request.</p></li>
    /// <li>
    /// <p>InProgress – This job has begun. You can start viewing the results in the output S3 location.</p></li>
    /// <li>
    /// <p>Completed – This job has successfully completed. View the output files in the output S3 location.</p></li>
    /// <li>
    /// <p>PartiallyCompleted – This job has partially completed. Not all of your records could be processed in time. View the output files in the output S3 location.</p></li>
    /// <li>
    /// <p>Failed – This job has failed. Check the failure message for any further details. For further assistance, reach out to the <a href="https://console.aws.amazon.com/support/home/">Amazon Web ServicesSupport Center</a>.</p></li>
    /// <li>
    /// <p>Stopped – This job was stopped by a user.</p></li>
    /// <li>
    /// <p>Stopping – This job is being stopped by a user.</p></li>
    /// </ul>
    pub fn status_equals(mut self, input: crate::types::ModelInvocationJobStatus) -> Self {
        self.status_equals = ::std::option::Option::Some(input);
        self
    }
    /// <p>Specify a status to filter for batch inference jobs whose statuses match the string you specify.</p>
    /// <p>The following statuses are possible:</p>
    /// <ul>
    /// <li>
    /// <p>Submitted – This job has been submitted to a queue for validation.</p></li>
    /// <li>
    /// <p>Validating – This job is being validated for the requirements described in <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-data.html">Format and upload your batch inference data</a>. The criteria include the following:</p>
    /// <ul>
    /// <li>
    /// <p>Your IAM service role has access to the Amazon S3 buckets containing your files.</p></li>
    /// <li>
    /// <p>Your files are .jsonl files and each individual record is a JSON object in the correct format. Note that validation doesn't check if the <code>modelInput</code> value matches the request body for the model.</p></li>
    /// <li>
    /// <p>Your files fulfill the requirements for file size and number of records. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html">Quotas for Amazon Bedrock</a>.</p></li>
    /// </ul></li>
    /// <li>
    /// <p>Scheduled – This job has been validated and is now in a queue. The job will automatically start when it reaches its turn.</p></li>
    /// <li>
    /// <p>Expired – This job timed out because it was scheduled but didn't begin before the set timeout duration. Submit a new job request.</p></li>
    /// <li>
    /// <p>InProgress – This job has begun. You can start viewing the results in the output S3 location.</p></li>
    /// <li>
    /// <p>Completed – This job has successfully completed. View the output files in the output S3 location.</p></li>
    /// <li>
    /// <p>PartiallyCompleted – This job has partially completed. Not all of your records could be processed in time. View the output files in the output S3 location.</p></li>
    /// <li>
    /// <p>Failed – This job has failed. Check the failure message for any further details. For further assistance, reach out to the <a href="https://console.aws.amazon.com/support/home/">Amazon Web ServicesSupport Center</a>.</p></li>
    /// <li>
    /// <p>Stopped – This job was stopped by a user.</p></li>
    /// <li>
    /// <p>Stopping – This job is being stopped by a user.</p></li>
    /// </ul>
    pub fn set_status_equals(mut self, input: ::std::option::Option<crate::types::ModelInvocationJobStatus>) -> Self {
        self.status_equals = input;
        self
    }
    /// <p>Specify a status to filter for batch inference jobs whose statuses match the string you specify.</p>
    /// <p>The following statuses are possible:</p>
    /// <ul>
    /// <li>
    /// <p>Submitted – This job has been submitted to a queue for validation.</p></li>
    /// <li>
    /// <p>Validating – This job is being validated for the requirements described in <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-data.html">Format and upload your batch inference data</a>. The criteria include the following:</p>
    /// <ul>
    /// <li>
    /// <p>Your IAM service role has access to the Amazon S3 buckets containing your files.</p></li>
    /// <li>
    /// <p>Your files are .jsonl files and each individual record is a JSON object in the correct format. Note that validation doesn't check if the <code>modelInput</code> value matches the request body for the model.</p></li>
    /// <li>
    /// <p>Your files fulfill the requirements for file size and number of records. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html">Quotas for Amazon Bedrock</a>.</p></li>
    /// </ul></li>
    /// <li>
    /// <p>Scheduled – This job has been validated and is now in a queue. The job will automatically start when it reaches its turn.</p></li>
    /// <li>
    /// <p>Expired – This job timed out because it was scheduled but didn't begin before the set timeout duration. Submit a new job request.</p></li>
    /// <li>
    /// <p>InProgress – This job has begun. You can start viewing the results in the output S3 location.</p></li>
    /// <li>
    /// <p>Completed – This job has successfully completed. View the output files in the output S3 location.</p></li>
    /// <li>
    /// <p>PartiallyCompleted – This job has partially completed. Not all of your records could be processed in time. View the output files in the output S3 location.</p></li>
    /// <li>
    /// <p>Failed – This job has failed. Check the failure message for any further details. For further assistance, reach out to the <a href="https://console.aws.amazon.com/support/home/">Amazon Web ServicesSupport Center</a>.</p></li>
    /// <li>
    /// <p>Stopped – This job was stopped by a user.</p></li>
    /// <li>
    /// <p>Stopping – This job is being stopped by a user.</p></li>
    /// </ul>
    pub fn get_status_equals(&self) -> &::std::option::Option<crate::types::ModelInvocationJobStatus> {
        &self.status_equals
    }
    /// <p>Specify a string to filter for batch inference jobs whose names contain the string.</p>
    pub fn name_contains(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.name_contains = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Specify a string to filter for batch inference jobs whose names contain the string.</p>
    pub fn set_name_contains(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.name_contains = input;
        self
    }
    /// <p>Specify a string to filter for batch inference jobs whose names contain the string.</p>
    pub fn get_name_contains(&self) -> &::std::option::Option<::std::string::String> {
        &self.name_contains
    }
    /// <p>The maximum number of results to return. If there are more results than the number that you specify, a <code>nextToken</code> value is returned. Use the <code>nextToken</code> in a request to return the next batch of results.</p>
    pub fn max_results(mut self, input: i32) -> Self {
        self.max_results = ::std::option::Option::Some(input);
        self
    }
    /// <p>The maximum number of results to return. If there are more results than the number that you specify, a <code>nextToken</code> value is returned. Use the <code>nextToken</code> in a request to return the next batch of results.</p>
    pub fn set_max_results(mut self, input: ::std::option::Option<i32>) -> Self {
        self.max_results = input;
        self
    }
    /// <p>The maximum number of results to return. If there are more results than the number that you specify, a <code>nextToken</code> value is returned. Use the <code>nextToken</code> in a request to return the next batch of results.</p>
    pub fn get_max_results(&self) -> &::std::option::Option<i32> {
        &self.max_results
    }
    /// <p>If there were more results than the value you specified in the <code>maxResults</code> field in a previous <code>ListModelInvocationJobs</code> request, the response would have returned a <code>nextToken</code> value. To see the next batch of results, send the <code>nextToken</code> value in another request.</p>
    pub fn next_token(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.next_token = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>If there were more results than the value you specified in the <code>maxResults</code> field in a previous <code>ListModelInvocationJobs</code> request, the response would have returned a <code>nextToken</code> value. To see the next batch of results, send the <code>nextToken</code> value in another request.</p>
    pub fn set_next_token(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.next_token = input;
        self
    }
    /// <p>If there were more results than the value you specified in the <code>maxResults</code> field in a previous <code>ListModelInvocationJobs</code> request, the response would have returned a <code>nextToken</code> value. To see the next batch of results, send the <code>nextToken</code> value in another request.</p>
    pub fn get_next_token(&self) -> &::std::option::Option<::std::string::String> {
        &self.next_token
    }
    /// <p>An attribute by which to sort the results.</p>
    pub fn sort_by(mut self, input: crate::types::SortJobsBy) -> Self {
        self.sort_by = ::std::option::Option::Some(input);
        self
    }
    /// <p>An attribute by which to sort the results.</p>
    pub fn set_sort_by(mut self, input: ::std::option::Option<crate::types::SortJobsBy>) -> Self {
        self.sort_by = input;
        self
    }
    /// <p>An attribute by which to sort the results.</p>
    pub fn get_sort_by(&self) -> &::std::option::Option<crate::types::SortJobsBy> {
        &self.sort_by
    }
    /// <p>Specifies whether to sort the results by ascending or descending order.</p>
    pub fn sort_order(mut self, input: crate::types::SortOrder) -> Self {
        self.sort_order = ::std::option::Option::Some(input);
        self
    }
    /// <p>Specifies whether to sort the results by ascending or descending order.</p>
    pub fn set_sort_order(mut self, input: ::std::option::Option<crate::types::SortOrder>) -> Self {
        self.sort_order = input;
        self
    }
    /// <p>Specifies whether to sort the results by ascending or descending order.</p>
    pub fn get_sort_order(&self) -> &::std::option::Option<crate::types::SortOrder> {
        &self.sort_order
    }
    /// Consumes the builder and constructs a [`ListModelInvocationJobsInput`](crate::operation::list_model_invocation_jobs::ListModelInvocationJobsInput).
    pub fn build(
        self,
    ) -> ::std::result::Result<
        crate::operation::list_model_invocation_jobs::ListModelInvocationJobsInput,
        ::aws_smithy_types::error::operation::BuildError,
    > {
        ::std::result::Result::Ok(crate::operation::list_model_invocation_jobs::ListModelInvocationJobsInput {
            submit_time_after: self.submit_time_after,
            submit_time_before: self.submit_time_before,
            status_equals: self.status_equals,
            name_contains: self.name_contains,
            max_results: self.max_results,
            next_token: self.next_token,
            sort_by: self.sort_by,
            sort_order: self.sort_order,
        })
    }
}
