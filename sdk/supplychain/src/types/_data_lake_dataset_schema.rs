// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>The schema details of the dataset. Note that for AWS Supply Chain dataset under <b>asc</b> namespace, it may have internal fields like connection_id that will be auto populated by data ingestion methods.</p>
#[non_exhaustive]
#[cfg_attr(feature = "serde-serialize", derive(::serde::Serialize))]
#[cfg_attr(feature = "serde-deserialize", derive(::serde::Deserialize))]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct DataLakeDatasetSchema {
    /// <p>The name of the dataset schema.</p>
    pub name: ::std::string::String,
    /// <p>The list of field details of the dataset schema.</p>
    pub fields: ::std::vec::Vec<crate::types::DataLakeDatasetSchemaField>,
    /// <p>The list of primary key fields for the dataset. Primary keys defined can help data ingestion methods to ensure data uniqueness: CreateDataIntegrationFlow's dedupe strategy will leverage primary keys to perform records deduplication before write to dataset; SendDataIntegrationEvent's UPSERT and DELETE can only work with dataset with primary keys. For more details, refer to those data ingestion documentations.</p>
    /// <p>Note that defining primary keys does not necessarily mean the dataset cannot have duplicate records, duplicate records can still be ingested if CreateDataIntegrationFlow's dedupe disabled or through SendDataIntegrationEvent's APPEND operation.</p>
    pub primary_keys: ::std::option::Option<::std::vec::Vec<crate::types::DataLakeDatasetPrimaryKeyField>>,
}
impl DataLakeDatasetSchema {
    /// <p>The name of the dataset schema.</p>
    pub fn name(&self) -> &str {
        use std::ops::Deref;
        self.name.deref()
    }
    /// <p>The list of field details of the dataset schema.</p>
    pub fn fields(&self) -> &[crate::types::DataLakeDatasetSchemaField] {
        use std::ops::Deref;
        self.fields.deref()
    }
    /// <p>The list of primary key fields for the dataset. Primary keys defined can help data ingestion methods to ensure data uniqueness: CreateDataIntegrationFlow's dedupe strategy will leverage primary keys to perform records deduplication before write to dataset; SendDataIntegrationEvent's UPSERT and DELETE can only work with dataset with primary keys. For more details, refer to those data ingestion documentations.</p>
    /// <p>Note that defining primary keys does not necessarily mean the dataset cannot have duplicate records, duplicate records can still be ingested if CreateDataIntegrationFlow's dedupe disabled or through SendDataIntegrationEvent's APPEND operation.</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.primary_keys.is_none()`.
    pub fn primary_keys(&self) -> &[crate::types::DataLakeDatasetPrimaryKeyField] {
        self.primary_keys.as_deref().unwrap_or_default()
    }
}
impl DataLakeDatasetSchema {
    /// Creates a new builder-style object to manufacture [`DataLakeDatasetSchema`](crate::types::DataLakeDatasetSchema).
    pub fn builder() -> crate::types::builders::DataLakeDatasetSchemaBuilder {
        crate::types::builders::DataLakeDatasetSchemaBuilder::default()
    }
}

/// A builder for [`DataLakeDatasetSchema`](crate::types::DataLakeDatasetSchema).
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
#[non_exhaustive]
pub struct DataLakeDatasetSchemaBuilder {
    pub(crate) name: ::std::option::Option<::std::string::String>,
    pub(crate) fields: ::std::option::Option<::std::vec::Vec<crate::types::DataLakeDatasetSchemaField>>,
    pub(crate) primary_keys: ::std::option::Option<::std::vec::Vec<crate::types::DataLakeDatasetPrimaryKeyField>>,
}
impl DataLakeDatasetSchemaBuilder {
    /// <p>The name of the dataset schema.</p>
    /// This field is required.
    pub fn name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The name of the dataset schema.</p>
    pub fn set_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.name = input;
        self
    }
    /// <p>The name of the dataset schema.</p>
    pub fn get_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.name
    }
    /// Appends an item to `fields`.
    ///
    /// To override the contents of this collection use [`set_fields`](Self::set_fields).
    ///
    /// <p>The list of field details of the dataset schema.</p>
    pub fn fields(mut self, input: crate::types::DataLakeDatasetSchemaField) -> Self {
        let mut v = self.fields.unwrap_or_default();
        v.push(input);
        self.fields = ::std::option::Option::Some(v);
        self
    }
    /// <p>The list of field details of the dataset schema.</p>
    pub fn set_fields(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::DataLakeDatasetSchemaField>>) -> Self {
        self.fields = input;
        self
    }
    /// <p>The list of field details of the dataset schema.</p>
    pub fn get_fields(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::DataLakeDatasetSchemaField>> {
        &self.fields
    }
    /// Appends an item to `primary_keys`.
    ///
    /// To override the contents of this collection use [`set_primary_keys`](Self::set_primary_keys).
    ///
    /// <p>The list of primary key fields for the dataset. Primary keys defined can help data ingestion methods to ensure data uniqueness: CreateDataIntegrationFlow's dedupe strategy will leverage primary keys to perform records deduplication before write to dataset; SendDataIntegrationEvent's UPSERT and DELETE can only work with dataset with primary keys. For more details, refer to those data ingestion documentations.</p>
    /// <p>Note that defining primary keys does not necessarily mean the dataset cannot have duplicate records, duplicate records can still be ingested if CreateDataIntegrationFlow's dedupe disabled or through SendDataIntegrationEvent's APPEND operation.</p>
    pub fn primary_keys(mut self, input: crate::types::DataLakeDatasetPrimaryKeyField) -> Self {
        let mut v = self.primary_keys.unwrap_or_default();
        v.push(input);
        self.primary_keys = ::std::option::Option::Some(v);
        self
    }
    /// <p>The list of primary key fields for the dataset. Primary keys defined can help data ingestion methods to ensure data uniqueness: CreateDataIntegrationFlow's dedupe strategy will leverage primary keys to perform records deduplication before write to dataset; SendDataIntegrationEvent's UPSERT and DELETE can only work with dataset with primary keys. For more details, refer to those data ingestion documentations.</p>
    /// <p>Note that defining primary keys does not necessarily mean the dataset cannot have duplicate records, duplicate records can still be ingested if CreateDataIntegrationFlow's dedupe disabled or through SendDataIntegrationEvent's APPEND operation.</p>
    pub fn set_primary_keys(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::DataLakeDatasetPrimaryKeyField>>) -> Self {
        self.primary_keys = input;
        self
    }
    /// <p>The list of primary key fields for the dataset. Primary keys defined can help data ingestion methods to ensure data uniqueness: CreateDataIntegrationFlow's dedupe strategy will leverage primary keys to perform records deduplication before write to dataset; SendDataIntegrationEvent's UPSERT and DELETE can only work with dataset with primary keys. For more details, refer to those data ingestion documentations.</p>
    /// <p>Note that defining primary keys does not necessarily mean the dataset cannot have duplicate records, duplicate records can still be ingested if CreateDataIntegrationFlow's dedupe disabled or through SendDataIntegrationEvent's APPEND operation.</p>
    pub fn get_primary_keys(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::DataLakeDatasetPrimaryKeyField>> {
        &self.primary_keys
    }
    /// Consumes the builder and constructs a [`DataLakeDatasetSchema`](crate::types::DataLakeDatasetSchema).
    /// This method will fail if any of the following fields are not set:
    /// - [`name`](crate::types::builders::DataLakeDatasetSchemaBuilder::name)
    /// - [`fields`](crate::types::builders::DataLakeDatasetSchemaBuilder::fields)
    pub fn build(self) -> ::std::result::Result<crate::types::DataLakeDatasetSchema, ::aws_smithy_types::error::operation::BuildError> {
        ::std::result::Result::Ok(crate::types::DataLakeDatasetSchema {
            name: self.name.ok_or_else(|| {
                ::aws_smithy_types::error::operation::BuildError::missing_field(
                    "name",
                    "name was not specified but it is required when building DataLakeDatasetSchema",
                )
            })?,
            fields: self.fields.ok_or_else(|| {
                ::aws_smithy_types::error::operation::BuildError::missing_field(
                    "fields",
                    "fields was not specified but it is required when building DataLakeDatasetSchema",
                )
            })?,
            primary_keys: self.primary_keys,
        })
    }
}
